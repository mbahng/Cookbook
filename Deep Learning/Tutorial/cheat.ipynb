{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "train_set = datasets.MNIST('./data', train=True, download=True)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_set_array = train_set.data.numpy() \n",
    "\n",
    "for i in range(len(train_set_array)): \n",
    "    train.append((train_set_array[i].reshape(-1, 1), train_set.targets.numpy()[i]))\n",
    "\n",
    "np.random.shuffle(train) \n",
    "\n",
    "N = len(train) \n",
    "X_train = np.hstack(tuple([train[i][0] for i in range(40000)])) / 255.\n",
    "Y_train = np.hstack(tuple([train[i][1] for i in range(40000)]))\n",
    "X_test = np.hstack(tuple([train[i][0] for i in range(40000, N)])) / 255.\n",
    "Y_test = np.hstack(tuple([train[i][1] for i in range(40000, N)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(): \n",
    "    W1 = np.random.uniform(-1, 1, size=(10, 784)) \n",
    "    b1 = np.random.uniform(-1, 1, size=(10, 1)) \n",
    "    W2 = np.random.uniform(-1, 1, size=(10, 10)) \n",
    "    b2 = np.random.uniform(-1, 1, size=(10, 1)) \n",
    "    \n",
    "    return W1, b1, W2, b2 \n",
    "\n",
    "def ReLU(Z): \n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def ReLU_d(Z): \n",
    "    return Z > 0\n",
    "\n",
    "def softMax(X:np.array): \n",
    "    x_max = np.max(X, axis=0)\n",
    "    X = X - x_max\n",
    "    return np.exp(X) / np.sum(np.exp(X), axis=0) \n",
    "\n",
    "def softMax_d(X:np.array): \n",
    "    return np.diag(X) - np.matmul(X, np.transpose(X))\n",
    "\n",
    "\n",
    "def one_hot(Y): \n",
    "    one_hot_Y = np.zeros((Y.size, 10))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1 \n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def forwardProp(W1, b1, W2, b2, X): \n",
    "    Z1 = np.matmul(W1, X) + b1\n",
    "    A1 = ReLU(Z1) \n",
    "    Z2 = np.matmul(W2, A1) + b2 \n",
    "    A2 = softMax(Z2) \n",
    "    return Z1, A1, Z2, A2 \n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    n, m = X.shape\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, 1)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_d(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, 1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1.reshape(10, 1)    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2.reshape(10, 1)    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = initializer()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forwardProp(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[1 5 1 ... 1 5 1] [5 9 5 ... 6 8 0]\n",
      "0.132025\n",
      "Iteration:  10\n",
      "[5 5 3 ... 3 6 0] [5 9 5 ... 6 8 0]\n",
      "0.304725\n",
      "Iteration:  20\n",
      "[5 4 3 ... 3 6 0] [5 9 5 ... 6 8 0]\n",
      "0.3733\n",
      "Iteration:  30\n",
      "[5 4 3 ... 3 6 0] [5 9 5 ... 6 8 0]\n",
      "0.412325\n",
      "Iteration:  40\n",
      "[5 4 3 ... 3 6 0] [5 9 5 ... 6 8 0]\n",
      "0.438275\n",
      "Iteration:  50\n",
      "[5 4 3 ... 3 8 0] [5 9 5 ... 6 8 0]\n",
      "0.46055\n",
      "Iteration:  60\n",
      "[5 4 3 ... 3 8 0] [5 9 5 ... 6 8 0]\n",
      "0.48\n",
      "Iteration:  70\n",
      "[5 4 3 ... 3 8 0] [5 9 5 ... 6 8 0]\n",
      "0.495925\n",
      "Iteration:  80\n",
      "[5 4 3 ... 3 8 0] [5 9 5 ... 6 8 0]\n",
      "0.5115\n",
      "Iteration:  90\n",
      "[5 4 3 ... 3 8 0] [5 9 5 ... 6 8 0]\n",
      "0.5252\n",
      "Iteration:  100\n",
      "[5 4 3 ... 3 8 0] [5 9 5 ... 6 8 0]\n",
      "0.538825\n",
      "Iteration:  110\n",
      "[5 4 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.55095\n",
      "Iteration:  120\n",
      "[5 4 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.563625\n",
      "Iteration:  130\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.574125\n",
      "Iteration:  140\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.5836\n",
      "Iteration:  150\n",
      "[9 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.5929\n",
      "Iteration:  160\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.602175\n",
      "Iteration:  170\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.610275\n",
      "Iteration:  180\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.619125\n",
      "Iteration:  190\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.627925\n",
      "Iteration:  200\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.636425\n",
      "Iteration:  210\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.643625\n",
      "Iteration:  220\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.65055\n",
      "Iteration:  230\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.657\n",
      "Iteration:  240\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.6638\n",
      "Iteration:  250\n",
      "[5 9 3 ... 3 5 0] [5 9 5 ... 6 8 0]\n",
      "0.671\n",
      "Iteration:  260\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.677\n",
      "Iteration:  270\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.6829\n",
      "Iteration:  280\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.688325\n",
      "Iteration:  290\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.694475\n",
      "Iteration:  300\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.6996\n",
      "Iteration:  310\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.70565\n",
      "Iteration:  320\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.71095\n",
      "Iteration:  330\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.7154\n",
      "Iteration:  340\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.719475\n",
      "Iteration:  350\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.723325\n",
      "Iteration:  360\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.72685\n",
      "Iteration:  370\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.730375\n",
      "Iteration:  380\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.73375\n",
      "Iteration:  390\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.737075\n",
      "Iteration:  400\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.740475\n",
      "Iteration:  410\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.743875\n",
      "Iteration:  420\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.7464\n",
      "Iteration:  430\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.748925\n",
      "Iteration:  440\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.75185\n",
      "Iteration:  450\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.7545\n",
      "Iteration:  460\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.7567\n",
      "Iteration:  470\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.759075\n",
      "Iteration:  480\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.761575\n",
      "Iteration:  490\n",
      "[5 9 3 ... 5 5 0] [5 9 5 ... 6 8 0]\n",
      "0.764\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
