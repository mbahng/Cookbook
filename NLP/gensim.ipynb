{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deep' 'enjoy' 'flying' 'learning' 'like' 'nlp']\n",
      "[[1 0 0 1 1 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]]\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(3, 6)\n",
      "       deep  enjoy  flying  learning  like  nlp\n",
      "Doc 1     1      0       0         1     1    0\n",
      "Doc 2     0      0       0         0     1    1\n",
      "Doc 3     0      1       1         0     0    0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "corpus = [\n",
    "    \"I like deep learning.\", \n",
    "    \"I like NLP.\", \n",
    "    \"I enjoy flying.\"\n",
    "]\n",
    "\n",
    "cvectorizer = CountVectorizer()\n",
    "X = cvectorizer.fit_transform(corpus)\n",
    "terms = cvectorizer.get_feature_names_out()\n",
    "\n",
    "# List of all terms in order of document-term matrix columns. \n",
    "print(terms)\n",
    "\n",
    "# Document term matrix \n",
    "print(X.toarray())\n",
    "\n",
    "# Data type of matrix and shape \n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "# [[1 0 0 1 1 0]\n",
    "#  [0 0 0 0 1 1]\n",
    "#  [0 1 1 0 0 0]]\n",
    "\n",
    "documentTermMatrix = pd.DataFrame(X.toarray(),\n",
    "                                  index=[\"Doc 1\", \"Doc 2\", \"Doc 3\", ],\n",
    "                                  columns=terms)\n",
    "\n",
    "print(documentTermMatrix.to_string())\n",
    "\n",
    "#        deep  enjoy  flying  learning  like  nlp\n",
    "# Doc 1     1      0       0         1     1    0\n",
    "# Doc 2     0      0       0         0     1    1\n",
    "# Doc 3     0      1       1         0     0    0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           deep     enjoy    flying  learning      like       nlp\n",
      "Doc 1  0.622766  0.000000  0.000000  0.622766  0.473630  0.000000\n",
      "Doc 2  0.000000  0.000000  0.000000  0.000000  0.605349  0.795961\n",
      "Doc 3  0.000000  0.707107  0.707107  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "corpus = [\n",
    "    \"I like deep learning.\", \n",
    "    \"I like NLP.\", \n",
    "    \"I enjoy flying.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "tfidfMatrix = pd.DataFrame(X.toarray(),\n",
    "                            index=[\"Doc 1\", \"Doc 2\", \"Doc 3\", ],\n",
    "                            columns=terms)\n",
    "\n",
    "print(tfidfMatrix)\n",
    "#            deep     enjoy    flying  learning      like       nlp\n",
    "# Doc 1  0.622766  0.000000  0.000000  0.622766  0.473630  0.000000\n",
    "# Doc 2  0.000000  0.000000  0.000000  0.000000  0.605349  0.795961\n",
    "# Doc 3  0.000000  0.707107  0.707107  0.000000  0.000000  0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some additional information after running SVD: \n",
      "[0.23711277 0.36855639]\n",
      "0.6056691599980445\n",
      "[1.13433283 1.        ]\n",
      "randomized\n",
      "----------\n",
      "Here are svd components: \n",
      "[[ 3.88212397e-01  4.56337927e-17  5.28752610e-17  3.88212397e-01\n",
      "   6.72600419e-01  4.96176326e-01]\n",
      " [ 6.31861587e-17  7.07106781e-01  7.07106781e-01 -1.78242739e-17\n",
      "  -5.31641590e-17 -6.92996404e-17]]\n",
      "----------\n",
      "Here is the resulting compressed matrix: \n",
      "[[ 8.02094437e-01  3.06972049e-18]\n",
      " [ 8.02094437e-01 -8.73426236e-17]\n",
      " [ 6.96564199e-17  1.00000000e+00]]\n",
      "----------\n",
      "        topic_1        topic2                 corpus\n",
      "0  8.020944e-01  3.069720e-18  I like deep learning.\n",
      "1  8.020944e-01 -8.734262e-17            I like NLP.\n",
      "2  6.965642e-17  1.000000e+00        I enjoy flying.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "# Here we run the SVD algorithm\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "lsa = svd.fit_transform(X)\n",
    "print(\"Some additional information after running SVD: \")\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)\n",
    "print(svd.algorithm)\n",
    "print(\"----------\")\n",
    "print(\"Here are svd components: \")\n",
    "print(svd.components_)\n",
    "print(\"----------\")\n",
    "print(\"Here is the resulting compressed matrix: \")\n",
    "print(lsa)\n",
    "print(\"----------\")\n",
    "\n",
    "topic_encoded_df: pd.DataFrame = pd.DataFrame(lsa, columns=['topic_1', 'topic2'])\n",
    "\n",
    "topic_encoded_df[\"corpus\"] = corpus\n",
    "\n",
    "print(topic_encoded_df.to_string())\n",
    "\n",
    "# https://github.com/sirajzade/learningVideos/blob/main/vectorizing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/mbahng/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, nltk\n",
    "from nltk.corpus import brown\n",
    "from gensim.models import Word2Vec\n",
    " \n",
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57158\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data to lowercase all words and remove single punctuation words\n",
    "document = brown.sents()\n",
    "\n",
    "data = []\n",
    "for sent in document:\n",
    "  new_sent = []\n",
    "  for word in sent:\n",
    "    new_word = word.lower()\n",
    "    if new_word[0] not in string.punctuation:\n",
    "      new_sent.append(new_word)\n",
    "  if len(new_sent) > 0:\n",
    "    data.append(new_sent)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57158\n",
      "22\n",
      "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place']\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data[0]))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f4880394e20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences = data,\n",
    "    vector_size = 50,\n",
    "    window = 10,\n",
    "    epochs = 20,\n",
    "    workers=6\n",
    ")\n",
    "\n",
    "model[\"love\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0745513  -1.8171308  -2.4329011  -0.3691842  -0.95292336 -0.54824775\n",
      "  1.1184701  -1.2525641  -0.7875846  -3.7816436  -1.341159    2.6486464\n",
      " -0.30800238 -2.7417247   0.17696398 -2.9048784   1.621813    0.49121374\n",
      "  0.4354661  -1.6528435  -2.4828649   0.4085583  -0.7043962   2.8490443\n",
      " -0.98837584  1.6951126  -1.607722    1.3588951  -0.03844598 -0.4779845\n",
      " -3.2942739   1.3696849   0.07875736  1.0799417  -1.6086684   0.6993245\n",
      "  1.5824703   1.5176587   1.626068    1.7591808  -1.3893017  -2.4028397\n",
      " -0.36541265  0.71958435  2.0678997  -1.6587187   1.6821662  -3.3152702\n",
      " -1.6718794  -1.6396806 ]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv[\"love\"])\n",
    "\n",
    "# [ 1.0745513  -1.8171308  -2.4329011  -0.3691842  -0.95292336 -0.54824775\n",
    "#   1.1184701  -1.2525641  -0.7875846  -3.7816436  -1.341159    2.6486464\n",
    "#  -0.30800238 -2.7417247   0.17696398 -2.9048784   1.621813    0.49121374\n",
    "#   0.4354661  -1.6528435  -2.4828649   0.4085583  -0.7043962   2.8490443\n",
    "#  -0.98837584  1.6951126  -1.607722    1.3588951  -0.03844598 -0.4779845\n",
    "#  -3.2942739   1.3696849   0.07875736  1.0799417  -1.6086684   0.6993245\n",
    "#   1.5824703   1.5176587   1.626068    1.7591808  -1.3893017  -2.4028397\n",
    "#  -0.36541265  0.71958435  2.0678997  -1.6587187   1.6821662  -3.3152702\n",
    "#  -1.6718794  -1.6396806 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I like deep learning.\", \n",
    "    \"I like NLP.\", \n",
    "    \"I enjoy flying.\"\n",
    "]\n",
    "\n",
    "for document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
